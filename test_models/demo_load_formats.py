"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –≤ —Ç—Ä–µ—Ö —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö

–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞–∫ –∑–∞–≥—Ä—É–∂–∞—Ç—å:
1. State dict (.pth) - —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞
2. –ü–æ–ª–Ω—É—é –º–æ–¥–µ–ª—å (_full.pth) - —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
3. TorchScript (.pt) - production-ready, –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞
"""

import torch
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ –ø—É—Ç—å
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.cnn_lstm import CNNLSTMSpamClassifier
from data_loader import load_emails, EmailDataset
from sklearn.model_selection import train_test_split


def demo_state_dict_loading():
    """–§–æ—Ä–º–∞—Ç 1: State Dict - —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞"""
    print("\n" + "="*70)
    print("–§–û–†–ú–ê–¢ 1: STATE DICT (.pth) - –¢–æ–ª—å–∫–æ –≤–µ—Å–∞")
    print("="*70)

    print("\nüìù –ß—Ç–æ –Ω—É–∂–Ω–æ:")
    print("  ‚úì –§–∞–π–ª —Å –≤–µ—Å–∞–º–∏ (best_cnn_lstm_model.pth)")
    print("  ‚úì –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –∫–ª–∞—Å—Å–∞ –º–æ–¥–µ–ª–∏")
    print("  ‚úì –í—Ä—É—á–Ω—É—é —É–∫–∞–∑–∞—Ç—å –≤—Å–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä—è
    print("\nüîß –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–ª–æ–≤–∞—Ä—è...")
    texts, labels = load_emails("../data/extracted/body")
    X_train, _, y_train, _ = train_test_split(
        texts, labels, test_size=0.3, random_state=42, stratify=labels
    )

    # –°—Ç—Ä–æ–∏–º —Å–ª–æ–≤–∞—Ä—å
    train_dataset = EmailDataset(X_train, y_train, max_len=1604)
    vocab_size = len(train_dataset.vocab)
    print(f"  ‚úì –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {vocab_size}")

    # –í–ê–ñ–ù–û: –ù—É–∂–Ω–æ –≤—Ä—É—á–Ω—É—é —É–∫–∞–∑–∞—Ç—å –≤—Å–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã!
    print("\nüèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏ (–≤—Ä—É—á–Ω—É—é —É–∫–∞–∑—ã–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)...")
    model = CNNLSTMSpamClassifier(
        vocab_size=vocab_size,
        embedding_dim=128,      # –í—Ä—É—á–Ω—É—é!
        num_filters=256,        # –í—Ä—É—á–Ω—É—é!
        filter_sizes=[3, 4, 5], # –í—Ä—É—á–Ω—É—é!
        lstm_hidden=256,        # –í—Ä—É—á–Ω—É—é!
        dropout=0.5             # –í—Ä—É—á–Ω—É—é!
    )

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
    print("\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞...")
    if os.path.exists('best_cnn_lstm_model.pth'):
        model.load_state_dict(torch.load('best_cnn_lstm_model.pth', map_location='cpu'))
        model.eval()
        print("  ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print(f"  ‚úì –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in model.parameters()):,}")
    else:
        print("  ‚ùå –§–∞–π–ª best_cnn_lstm_model.pth –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("     –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å: python test_cnn_lstm.py")

    print("\nüí° –ü–ª—é—Å—ã:  –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞")
    print("üí° –ú–∏–Ω—É—Å—ã: –ù—É–∂–Ω–æ –ø–æ–º–Ω–∏—Ç—å –≤—Å–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã")


def demo_full_model_loading():
    """–§–æ—Ä–º–∞—Ç 2: –ü–æ–ª–Ω–∞—è –º–æ–¥–µ–ª—å - —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
    print("\n" + "="*70)
    print("–§–û–†–ú–ê–¢ 2: –ü–û–õ–ù–ê–Ø –ú–û–î–ï–õ–¨ (_full.pth) - –í–µ—Å–∞ + –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
    print("="*70)

    print("\nüìù –ß—Ç–æ –Ω—É–∂–Ω–æ:")
    print("  ‚úì –§–∞–π–ª —Å –ø–æ–ª–Ω–æ–π –º–æ–¥–µ–ª—å—é (best_cnn_lstm_full.pth)")
    print("  ‚úì –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –∫–ª–∞—Å—Å–∞ –º–æ–¥–µ–ª–∏")
    print("  ‚úó –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä—è
    print("\nüîß –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–ª–æ–≤–∞—Ä—è...")
    texts, labels = load_emails("../data/extracted/body")
    X_train, _, y_train, _ = train_test_split(
        texts, labels, test_size=0.3, random_state=42, stratify=labels
    )

    # –°—Ç—Ä–æ–∏–º —Å–ª–æ–≤–∞—Ä—å
    train_dataset = EmailDataset(X_train, y_train, max_len=1604)
    vocab_size = len(train_dataset.vocab)
    print(f"  ‚úì –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {vocab_size}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint
    print("\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ checkpoint...")
    if os.path.exists('best_cnn_lstm_full.pth'):
        checkpoint = torch.load('best_cnn_lstm_full.pth', map_location='cpu')

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã!
        hyperparams = checkpoint['hyperparameters']
        print("\n‚ú® –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:")
        for key, value in hyperparams.items():
            print(f"  - {key}: {value}")

        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        print("\nüèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (—Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏)...")
        model = CNNLSTMSpamClassifier(
            vocab_size=vocab_size,
            **hyperparams  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã!
        )

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        print("  ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—É—á–µ–Ω–∏–∏
        if 'training_info' in checkpoint:
            info = checkpoint['training_info']
            print("\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—É—á–µ–Ω–∏–∏:")
            print(f"  - –≠–ø–æ—Ö–∞: {info['epoch']}")
            print(f"  - Accuracy: {info['accuracy']*100:.2f}%")
            print(f"  - F1-Score: {info['f1']*100:.2f}%")
            print(f"  - Precision: {info['precision']*100:.2f}%")
            print(f"  - Recall: {info['recall']*100:.2f}%")

        print(f"\n  ‚úì –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in model.parameters()):,}")
    else:
        print("  ‚ùå –§–∞–π–ª best_cnn_lstm_full.pth –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("     –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å: python test_cnn_lstm.py")

    print("\nüí° –ü–ª—é—Å—ã:  –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ + –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")
    print("üí° –ú–∏–Ω—É—Å—ã: –¢—Ä–µ–±—É–µ—Ç –∫–ª–∞—Å—Å –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ")


# def demo_torchscript_loading():
#     """–§–æ—Ä–º–∞—Ç 3: TorchScript - production-ready"""
#     print("\n" + "="*70)
#     print("–§–û–†–ú–ê–¢ 3: TORCHSCRIPT (.pt) - Production-ready")
#     print("="*70)
#
#     print("\nüìù –ß—Ç–æ –Ω—É–∂–Ω–æ:")
#     print("  ‚úì –§–∞–π–ª TorchScript (best_cnn_lstm_traced.pt)")
#     print("  ‚úó –ù–ï —Ç—Ä–µ–±—É–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –∫–ª–∞—Å—Å–∞ –º–æ–¥–µ–ª–∏!")
#     print("  ‚úó –ù–ï —Ç—Ä–µ–±—É–µ—Ç –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã!")
#
#     # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
#     print("\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ TorchScript –º–æ–¥–µ–ª–∏...")
#     if os.path.exists('best_cnn_lstm_traced.pt'):
#         # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ë–ï–ó –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–∞!
#         model = torch.jit.load('best_cnn_lstm_traced.pt', map_location='cpu')
#         model.eval()
#         print("  ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
#
#         # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
#         print("\nüß™ –¢–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ...")
#         # –°–æ–∑–¥–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ —ç—Ç–æ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç)
#         test_input = torch.randint(0, 30000, (1, 1604))
#
#         with torch.no_grad():
#             output = model(test_input)
#             probabilities = torch.softmax(output, dim=1)
#             prediction = torch.argmax(probabilities, dim=1).item()
#
#         print(f"  ‚úì –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!")
#         print(f"  - –í—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏: {output.shape}")
#         print(f"  - –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: Ham={probabilities[0][0]:.4f}, Spam={probabilities[0][1]:.4f}")
#         print(f"  - –ö–ª–∞—Å—Å: {'SPAM' if prediction == 1 else 'HAM'}")
#
#     else:
#         print("  ‚ùå –§–∞–π–ª best_cnn_lstm_traced.pt –Ω–µ –Ω–∞–π–¥–µ–Ω!")
#         print("     –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å: python test_cnn_lstm.py")
#
#     print("\nüí° –ü–ª—é—Å—ã:  –ù–µ —Ç—Ä–µ–±—É–µ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ, production-ready")
#     print("üí° –ú–∏–Ω—É—Å—ã: –ù–µ–ª—å–∑—è –∏–∑–º–µ–Ω—è—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É, –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è")
#     print("üí° –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –¥—Ä—É–≥–∏–µ —Å–∏—Å—Ç–µ–º—ã, —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤ production")


def compare_file_sizes():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ —Ñ–∞–π–ª–æ–≤"""
    print("\n" + "="*70)
    print("–°–†–ê–í–ù–ï–ù–ò–ï –†–ê–ó–ú–ï–†–û–í –§–ê–ô–õ–û–í")
    print("="*70 + "\n")

    files = [
        ('best_cnn_lstm_model.pth', 'State Dict'),
        ('best_cnn_lstm_full.pth', '–ü–æ–ª–Ω–∞—è –º–æ–¥–µ–ª—å'),
        ('best_cnn_lstm_traced.pt', 'TorchScript')
    ]

    print(f"{'–§–∞–π–ª':<30} {'–§–æ—Ä–º–∞—Ç':<20} {'–†–∞–∑–º–µ—Ä':<15}")
    print("-" * 70)

    for filename, format_name in files:
        if os.path.exists(filename):
            size_bytes = os.path.getsize(filename)
            size_mb = size_bytes / (1024 * 1024)
            print(f"{filename:<30} {format_name:<20} {size_mb:>8.2f} MB")
        else:
            print(f"{filename:<30} {format_name:<20} {'–Ω–µ –Ω–∞–π–¥–µ–Ω':>15}")


def main():
    print("\n" + "="*70)
    print("üéì –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –¢–†–ï–• –§–û–†–ú–ê–¢–û–í –°–û–•–†–ê–ù–ï–ù–ò–Ø –ú–û–î–ï–õ–ï–ô PYTORCH")
    print("="*70)

    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∫–∞–∂–¥–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
    demo_state_dict_loading()
    demo_full_model_loading()
    # demo_torchscript_loading()

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤
    compare_file_sizes()

    # –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("\n" + "="*70)
    print("üìå –ò–¢–û–ì–û–í–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
    print("="*70)
    print("""
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –°—Ü–µ–Ω–∞—Ä–∏–π                    ‚îÇ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã, –¥–æ–æ–±—É—á–µ–Ω–∏–µ    ‚îÇ State Dict (.pth)                     ‚îÇ
‚îÇ –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞, –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ‚îÇ –ü–æ–ª–Ω–∞—è –º–æ–¥–µ–ª—å (_full.pth)             ‚îÇ
‚îÇ                             ‚îÇ                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


""")

    print("="*70 + "\n")


if __name__ == "__main__":
    main()


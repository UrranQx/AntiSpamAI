# üíæ –§–æ—Ä–º–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π PyTorch

–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –∫–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ **—Ç—Ä–µ—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö** –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.

---

## üìã –û–±–∑–æ—Ä —Ñ–æ—Ä–º–∞—Ç–æ–≤

| –§–æ—Ä–º–∞—Ç | –§–∞–π–ª | –†–∞–∑–º–µ—Ä | –¢—Ä–µ–±—É–µ—Ç –∫–æ–¥ | Production | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|------|--------|-------------|------------|----------|
| **State Dict** | `*.pth` | ~5-10 –ú–ë | ‚úÖ –î–∞ | ‚ùå | –¢–æ–ª—å–∫–æ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ |
| **Full Model** | `*_full.pth` | ~10-15 –ú–ë | ‚úÖ –î–∞ | ‚ö†Ô∏è | –í–µ—Å–∞ + –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã + –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ |
| **TorchScript** | `*.pt` | ~10-15 –ú–ë | ‚ùå –ù–µ—Ç | ‚úÖ | Production-ready, standalone |

---

## 1Ô∏è‚É£ State Dict (`.pth`)

### –ß—Ç–æ —ç—Ç–æ?
–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ–ª—å–∫–æ **–≤–µ—Å–∞ (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã)** –º–æ–¥–µ–ª–∏ –≤ –≤–∏–¥–µ —Å–ª–æ–≤–∞—Ä—è.

### –ß—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è?
```python
{
    'embedding.weight': tensor(...),
    'conv1.weight': tensor(...),
    'lstm.weight_ih_l0': tensor(...),
    ...
}
```

### –ö–∞–∫ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å?
```python
torch.save(model.state_dict(), 'best_model.pth')
```

### –ö–∞–∫ –∑–∞–≥—Ä—É–∂–∞—Ç—å?
```python
# –ù—É–∂–Ω–æ –í–†–£–ß–ù–£–Æ —Å–æ–∑–¥–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏!
model = CNNLSTMSpamClassifier(
    vocab_size=30000,
    embedding_dim=128,
    num_filters=256,
    lstm_hidden=256,
    dropout=0.5
)
model.load_state_dict(torch.load('best_model.pth'))
model.eval()
```

### ‚úÖ –ü–ª—é—Å—ã
- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
- –ë—ã—Å—Ç—Ä–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫–∞
- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –≤ PyTorch

### ‚ùå –ú–∏–Ω—É—Å—ã
- –ù—É–∂–µ–Ω –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –∫–ª–∞—Å—Å–∞ –º–æ–¥–µ–ª–∏
- –ù—É–∂–Ω–æ –≤—Ä—É—á–Ω—É—é —É–∫–∞–∑—ã–≤–∞—Ç—å –≤—Å–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
- –õ–µ–≥–∫–æ –¥–æ–ø—É—Å—Ç–∏—Ç—å –æ—à–∏–±–∫—É –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö

### üéØ –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å?
- –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞
- –ö–æ–≥–¥–∞ —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –∫—Ä–∏—Ç–∏—á–µ–Ω
- –í–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞

---

## 2Ô∏è‚É£ Full Model (`_full.pth`)

### –ß—Ç–æ —ç—Ç–æ?
–°–æ—Ö—Ä–∞–Ω—è–µ—Ç **–≤–µ—Å–∞ + –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã + –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–∏—è** –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ.

### –ß—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è?
```python
{
    'model_state_dict': {...},  # –í–µ—Å–∞ –º–æ–¥–µ–ª–∏
    'model': model,             # –í—Å—è –º–æ–¥–µ–ª—å (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    'vocab_size': 30000,
    'max_len': 1604,
    'hyperparameters': {
        'embedding_dim': 128,
        'num_filters': 256,
        'filter_sizes': [3, 4, 5],
        'lstm_hidden': 256,
        'dropout': 0.5
    },
    'training_info': {
        'epoch': 10,
        'accuracy': 0.9849,
        'f1': 0.9772,
        'precision': 0.9808,
        'recall': 0.9737
    }
}
```

### –ö–∞–∫ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å?
```python
torch.save({
    'model_state_dict': model.state_dict(),
    'vocab_size': vocab_size,
    'max_len': MAX_LEN,
    'hyperparameters': {
        'embedding_dim': EMBEDDING_DIM,
        'num_filters': NUM_FILTERS,
        'filter_sizes': FILTER_SIZES,
        'lstm_hidden': LSTM_HIDDEN,
        'dropout': DROPOUT
    },
    'training_info': {
        'epoch': epoch + 1,
        'accuracy': accuracy,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }
}, 'best_model_full.pth')
```

### –ö–∞–∫ –∑–∞–≥—Ä—É–∂–∞—Ç—å?
```python
# –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint
checkpoint = torch.load('best_model_full.pth')

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã!
hyperparams = checkpoint['hyperparameters']
print(f"–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {hyperparams}")

# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
model = CNNLSTMSpamClassifier(
    vocab_size=vocab_size,
    **hyperparams  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞!
)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# –ß–∏—Ç–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—É—á–µ–Ω–∏–∏
info = checkpoint['training_info']
print(f"Accuracy: {info['accuracy']*100:.2f}%")
```

### ‚úÖ –ü–ª—é—Å—ã
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–± –æ–±—É—á–µ–Ω–∏–∏
- –ú–µ–Ω—å—à–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—à–∏–±–æ–∫
- –õ–µ–≥–∫–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### ‚ùå –ú–∏–Ω—É—Å—ã
- –¢—Ä–µ–±—É–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –∫–ª–∞—Å—Å–∞ –º–æ–¥–µ–ª–∏
- –ù–µ–º–Ω–æ–≥–æ –±–æ–ª—å—à–∏–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
- –ù–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é portable

### üéØ –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å?
- –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ
- –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
- –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- –ö–æ–º–∞–Ω–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞



---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

| –û–ø–µ—Ä–∞—Ü–∏—è | State Dict | Full Model | 
|----------|-----------|------------|
| –í—Ä–µ–º—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è | 0.5 —Å–µ–∫ | 0.6 —Å–µ–∫ |
| –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ | 0.3 —Å–µ–∫ | 0.4 —Å–µ–∫ | 
| –°–∫–æ—Ä–æ—Å—Ç—å inference | 100% | 100% | 
| –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ | 5 –ú–ë | 10 –ú–ë | 

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É

### –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –º–æ–¥–µ–ª–∏ (–≤—ã):
```
–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã         ‚Üí State Dict (.pth)
–°–æ–≤–º–µ—Å—Ç–Ω–∞—è —Ä–∞–±–æ—Ç–∞    ‚Üí Full Model (_full.pth)
```

### –î–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä–æ–≤ (–∫–æ–ª–ª–µ–≥–∏):
```
–ù—É–∂–Ω–∞ –≥–∏–±–∫–æ—Å—Ç—å       ‚Üí Full Model (_full.pth)
–ï—Å—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥    ‚Üí State Dict (.pth)
```

### –î–ª—è production:
```
–ú–æ–±–∏–ª—å–Ω—ã–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ ‚Üí TorchScript Mobile
Edge —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞      ‚Üí TorchScript –∏–ª–∏ ONNX
```

---

## üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–µ–∂–¥—É —Ñ–æ—Ä–º–∞—Ç–∞–º–∏

### State Dict ‚Üí Full Model
```python
checkpoint = torch.load('model.pth')
torch.save({
    'model_state_dict': checkpoint,
    'hyperparameters': {...},
    'training_info': {...}
}, 'model_full.pth')
```

### Full Model ‚Üí TorchScript
```python
checkpoint = torch.load('model_full.pth')
model = CNNLSTMSpamClassifier(vocab_size, **checkpoint['hyperparameters'])
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

example_input = torch.randint(0, vocab_size, (1, max_len))
traced = torch.jit.trace(model, example_input)
traced.save('model_traced.pt')
```

---

## üìù –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è


### –ó–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ (Full Model)
```python
import torch
from models.cnn_lstm import CNNLSTMSpamClassifier

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
checkpoint = torch.load('best_cnn_lstm_full.pth')
model = CNNLSTMSpamClassifier(
    vocab_size=30000,
    **checkpoint['hyperparameters']
)
model.load_state_dict(checkpoint['model_state_dict'])

# –ú–æ–∂–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ
optimizer = torch.optim.Adam(model.parameters())
# ...
```

---



## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [PyTorch Saving & Loading Models](https://pytorch.org/tutorials/beginner/saving_loading_models.html)
- [TorchScript Documentation](https://pytorch.org/docs/stable/jit.html)
- [ONNX Export (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)](https://pytorch.org/docs/stable/onnx.html)

---

**–°–æ–∑–¥–∞–Ω–æ:** AntiSpam AI Project  
**–î–∞—Ç–∞:** 2025  
**–í–µ—Ä—Å–∏—è:** 1.0

